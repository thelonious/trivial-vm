package com.kevlindev.tokens;

import java.util.ArrayList;
import java.util.Map;
import beaver.*;
import java.util.List;
import java.util.HashMap;
import java.io.IOException;

/**
 * This class is a LALR parser generated by
 * <a href="http://beaver.sourceforge.net">Beaver</a> v0.9.6.1
 * from the grammar specification "token.grammar".
 */
public class TokenParser extends Parser {

	static final ParsingTables PARSING_TABLES = new ParsingTables(
		"U9nzKDSEmZ0Cl9JIqZs03ea7FhNVp2hRN8DLLHKYqequFainWBq85bZ2XOyGsr4RbF3We9G" +
		"3DaYnHeQSl4A2015Y5AXGymRs6yvmESKRDMJMuQl3NCHKm1a36yvto36h0$lCjntiSGTIRu" +
		"X8VKNKwbkYK1#g9ftcfk3P4SsiPaIa$zK$wyjKFTNYJsyvyUrNv6tvQVbX#KvSYLukSfAZd" +
		"6tr9g$X1zoIiTjAg26tE4NCUanDgIdV8qN#0IsDC#0=");

	public TokenNode parse(String source) {
		TokenLexer lexer = new TokenLexer();

		lexer.setSource(source);

		Object result = null;

		try {
			result = parse(lexer);
		} catch (IOException e) {
			e.printStackTrace();
		} catch (Exception e) {
			e.printStackTrace();
		}

		return (result instanceof TokenNode) ? (TokenNode) result : null;
	}

	public TokenParser() {
		super(PARSING_TABLES);
	}

	protected Symbol invokeReduceAction(int rule_num, int offset) {
		switch(rule_num) {
			case 0: // Grammar = Statements.ss
			{
					final Symbol _symbol_ss = _symbols[offset + 1];
					final List<TokenNode> ss = (List<TokenNode>) _symbol_ss.value;
					
			TokenNode result = new TokenNode(TokenType.ROOT);
			
			result.addChildren(ss);
			
			return new Symbol(result);
			}
			case 1: // Statements = Statements.ss Statement.s
			{
					final Symbol _symbol_ss = _symbols[offset + 1];
					final List<TokenNode> ss = (List<TokenNode>) _symbol_ss.value;
					final Symbol _symbol_s = _symbols[offset + 2];
					final TokenNode s = (TokenNode) _symbol_s.value;
					
			ss.add(s);
			
			return new Symbol(ss);
			}
			case 2: // Statements = Statement.s
			{
					final Symbol _symbol_s = _symbols[offset + 1];
					final TokenNode s = (TokenNode) _symbol_s.value;
					
			List<TokenNode> result = new ArrayList<TokenNode>();
			
			result.add(s);
			
			return new Symbol(result);
			}
			case 3: // Statement = PACKAGE.p EQUAL IDENTIFIER.i
			{
					final Symbol p = _symbols[offset + 1];
					final Symbol i = _symbols[offset + 3];
					
			TokenNode result = new TokenNode(p);
			
			result.addChild(new TokenNode(i));
			
			return result;
			}
			case 4: // Statement = LANGUAGE.l EQUAL IDENTIFIER.i
			{
					final Symbol l = _symbols[offset + 1];
					final Symbol i = _symbols[offset + 3];
					
			TokenNode result = new TokenNode(l);
			
			result.addChild(new TokenNode(i));
			
			return result;
			}
			case 5: // Statement = KEYWORDS.k EQUAL List.l
			{
					final Symbol k = _symbols[offset + 1];
					final Symbol _symbol_l = _symbols[offset + 3];
					final List<TokenNode> l = (List<TokenNode>) _symbol_l.value;
					
			TokenNode result = new TokenNode(k);
			
			result.addChildren(l);
			
			return result;
			}
			case 6: // Statement = OPERATORS.o EQUAL List.l
			{
					final Symbol o = _symbols[offset + 1];
					final Symbol _symbol_l = _symbols[offset + 3];
					final List<TokenNode> l = (List<TokenNode>) _symbol_l.value;
					
			TokenNode result = new TokenNode(o);
			
			result.addChildren(l);
			
			return result;
			}
			case 7: // List = LBRACKET RBRACKET
			{
					
			return new Symbol(new ArrayList<TokenNode>());
			}
			case 8: // List = LBRACKET Identifiers.i RBRACKET
			{
					final Symbol _symbol_i = _symbols[offset + 2];
					final List<TokenNode> i = (List<TokenNode>) _symbol_i.value;
					
			return new Symbol(i);
			}
			case 9: // Identifiers = Identifiers.is Word.w
			{
					final Symbol _symbol_is = _symbols[offset + 1];
					final List<TokenNode> is = (List<TokenNode>) _symbol_is.value;
					final Symbol _symbol_w = _symbols[offset + 2];
					final TokenNode w = (TokenNode) _symbol_w.value;
					
			is.add(w);
			
			return new Symbol(is);
			}
			case 10: // Identifiers = Word.w
			{
					final Symbol _symbol_w = _symbols[offset + 1];
					final TokenNode w = (TokenNode) _symbol_w.value;
					
			List<TokenNode> result = new ArrayList<TokenNode>();
			
			result.add(w);
			
			return new Symbol(result);
			}
			case 11: // Word = IDENTIFIER.i
			{
					final Symbol i = _symbols[offset + 1];
					
			return new TokenNode(i);
			}
			case 12: // Word = STRING.s
			{
					final Symbol s = _symbols[offset + 1];
					
			return new TokenNode(s);
			}
			default:
				throw new IllegalArgumentException("unknown production #" + rule_num);
		}
	}
}
